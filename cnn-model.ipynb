{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-13T17:30:51.551021Z","iopub.execute_input":"2022-12-13T17:30:51.551477Z","iopub.status.idle":"2022-12-13T17:30:51.601489Z","shell.execute_reply.started":"2022-12-13T17:30:51.551401Z","shell.execute_reply":"2022-12-13T17:30:51.600497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/test/test/testX.pt\n/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/train/train/trainY.pt\n/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/train/train/trainX.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy\nimport torchvision.models as m\nfrom torchvision import datasets, transforms\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport os\nimport numpy as np\nimport pickle as pkl\nfrom torchvision.utils import save_image\nimport cv2\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport pickle\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:44:23.198689Z","iopub.execute_input":"2022-12-13T17:44:23.199583Z","iopub.status.idle":"2022-12-13T17:44:23.206985Z","shell.execute_reply.started":"2022-12-13T17:44:23.199541Z","shell.execute_reply":"2022-12-13T17:44:23.206071Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:44:27.519703Z","iopub.execute_input":"2022-12-13T17:44:27.520098Z","iopub.status.idle":"2022-12-13T17:44:27.615893Z","shell.execute_reply.started":"2022-12-13T17:44:27.520064Z","shell.execute_reply":"2022-12-13T17:44:27.614639Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:44:29.253075Z","iopub.execute_input":"2022-12-13T17:44:29.253483Z","iopub.status.idle":"2022-12-13T17:44:29.262963Z","shell.execute_reply.started":"2022-12-13T17:44:29.253449Z","shell.execute_reply":"2022-12-13T17:44:29.261833Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"trainx = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/train/train/trainX.pt')\ntrainy = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/train/train/trainY.pt')\ntestx = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/test/test/testX.pt')\n\nnum_train = trainx[0].shape[0]\nnum_test = testx[0].shape[0]\n\nos.makedirs('./lazydata', exist_ok=True)\n\n# Save train data\nos.makedirs('./lazydata/train', exist_ok=True)\nos.makedirs('./lazydata/train/X', exist_ok=True)\nos.makedirs('./lazydata/train/Y', exist_ok=True)\nfor i in range(num_train):\n    os.makedirs('./lazydata/train/X/{}'.format(i), exist_ok=True)\n    # rgb\n    os.makedirs('./lazydata/train/X/{}/rgb'.format(i), exist_ok=True)\n    for j in range(3):\n        save_image(trainx[0][i][j]/255, './lazydata/train/X/{}/rgb/{}.png'.format(i, j))\n    # depth\n    depth = trainx[1][i].numpy()\n    np.save('./lazydata/train/X/{}/depth.npy'.format(i), depth)\n    # field id\n    pkl.dump(trainx[2][i], open('./lazydata/train/X/{}/field_id.pkl'.format(i), 'wb'))\n\n    y = trainy[0][i].numpy()\n    np.save('./lazydata/train/Y/{}.npy'.format(i), y)\nprint(\"Saved train data\")\n\n# Save test data\nos.makedirs('./lazydata/test', exist_ok=True)\nos.makedirs('./lazydata/test/X', exist_ok=True)\nfor i in range(num_test):\n    os.makedirs('./lazydata/test/X/{}'.format(i), exist_ok=True)\n    # rgb\n    os.makedirs('./lazydata/test/X/{}/rgb'.format(i), exist_ok=True)\n    for j in range(3):\n        save_image(testx[0][i][j]/255, './lazydata/test/X/{}/rgb/{}.png'.format(i, j))\n    # depth\n    depth = testx[1][i].numpy()\n    np.save('./lazydata/test/X/{}/depth.npy'.format(i), depth)\n    # field id\n    pkl.dump(testx[2][i], open('./lazydata/test/X/{}/field_id.pkl'.format(i), 'wb'))\n\nprint(\"Saved test data\")","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:31:37.698827Z","iopub.execute_input":"2022-12-13T17:31:37.699449Z","iopub.status.idle":"2022-12-13T17:38:29.993365Z","shell.execute_reply.started":"2022-12-13T17:31:37.699397Z","shell.execute_reply":"2022-12-13T17:38:29.992329Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Saved train data\nSaved test data\n","output_type":"stream"}]},{"cell_type":"code","source":"class lazyloaddata(Dataset):\n    def __init__(self,path,train=True,transform=None):\n        self.transform = transform\n        path1 = path + ('train/' if train else 'test/')\n        \n        self.pathX = path1+'X/'\n        self.pathY = path+'train/Y/'\n        \n        self.data = os.listdir(self.pathX)\n        \n    def __getitem__(self,idx):\n        f = self.data[idx]\n        img0 = cv2.imread(self.pathX+f+'/rgb/0.png')\n        img1 = cv2.imread(self.pathX+f+'/rgb/1.png')\n        img2 = cv2.imread(self.pathX+f+'/rgb/2.png')\n        if self.transform is not None:\n            '''\n            img0 = cv2.normalize(img0,None,alpha=0,beta=1,norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n            img1 = cv2.normalize(img1,None,alpha=0,beta=1,norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n            img2 = cv2.normalize(img2,None,alpha=0,beta=1,norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n            '''\n            \n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n        depth = np.load(self.pathX+f+'/depth.npy')\n        \n        fieldid = pkl.load(open(self.pathX+f+'/field_id.pkl','rb'))\n        \n        Y = np.load(self.pathY+f+'.npy')\n        Y*=1000\n        \n        return (img0,img1,img2,depth,fieldid), Y\n    \n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:28.889298Z","iopub.execute_input":"2022-12-13T20:50:28.889991Z","iopub.status.idle":"2022-12-13T20:50:28.901568Z","shell.execute_reply.started":"2022-12-13T20:50:28.889951Z","shell.execute_reply":"2022-12-13T20:50:28.900368Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:39:32.581093Z","iopub.execute_input":"2022-12-13T17:39:32.581447Z","iopub.status.idle":"2022-12-13T17:39:32.586796Z","shell.execute_reply.started":"2022-12-13T17:39:32.581417Z","shell.execute_reply":"2022-12-13T17:39:32.585619Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = lazyloaddata('/kaggle/working/lazydata/', train = True, transform = transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:39:34.766654Z","iopub.execute_input":"2022-12-13T17:39:34.767409Z","iopub.status.idle":"2022-12-13T17:39:34.777830Z","shell.execute_reply.started":"2022-12-13T17:39:34.767361Z","shell.execute_reply":"2022-12-13T17:39:34.776237Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"mean = 0\ncount = 0\nmean1 = 0\nmean2 = 0\nstd = 0\nstd1 = 0\nstd2 = 0\nfor batch_id , ((img0,img1,img2,depth,fieldid), Y ) in enumerate(train_loader):\n    mean+=img0.mean()\n    mean1+=img1.mean()\n    mean2+=img2.mean()\n    std+=img0.std()\n    std1+=img1.std()\n    std2+=img2.std()\n    count=count+1\nprint(mean/count)\nprint(mean1/count)\nprint(mean2/count)\nprint(std/count)\nprint(std1/count)\nprint(std2/count)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:39:36.667082Z","iopub.execute_input":"2022-12-13T17:39:36.667436Z","iopub.status.idle":"2022-12-13T17:40:38.177070Z","shell.execute_reply.started":"2022-12-13T17:39:36.667407Z","shell.execute_reply":"2022-12-13T17:40:38.175932Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tensor(0.4159)\ntensor(0.4860)\ntensor(0.4806)\ntensor(0.2044)\ntensor(0.2327)\ntensor(0.2379)\n","output_type":"stream"}]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomInvert(),\n    #transforms.RandomRotation((-90,90)),\n    #transforms.RandomGrayscale(0.1),\n    #transforms.GaussianBlur(kernel_size=7),\n    #transforms.RandomRotation(30), #Just added\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.4159, 0.4860, 0.4806], std = [0.2044, 0.2327, 0.2379])\n])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:34.128276Z","iopub.execute_input":"2022-12-13T20:50:34.129032Z","iopub.status.idle":"2022-12-13T20:50:34.136164Z","shell.execute_reply.started":"2022-12-13T20:50:34.128991Z","shell.execute_reply":"2022-12-13T20:50:34.134782Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_dataset = lazyloaddata('/kaggle/working/lazydata/',transform = transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:36.226732Z","iopub.execute_input":"2022-12-13T20:50:36.227122Z","iopub.status.idle":"2022-12-13T20:50:36.241346Z","shell.execute_reply.started":"2022-12-13T20:50:36.227087Z","shell.execute_reply":"2022-12-13T20:50:36.240212Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"res18 = m.resnet50()\n'''\nresnet50(weights=None)\nresnet50()\nresnet50(pretrained=False)  # deprecated\nresnet50(False)  # deprecated\n'''\n\n\nres18.train()\nres18.float()\nres18.conv1 = nn.Conv2d(12,64,kernel_size=7,stride=2,padding=3,bias=False)\nres18.fc = nn.Linear(in_features=2048, out_features=12) \n\nweight = res18.conv1.weight.clone()\n\n'''\nFrom the website:\nhttps://stackoverflow.com/questions/62629114/how-to-modify-resnet-50-with-4-channels-as-input-using-pre-trained-weights-in-py\n'''\nwith torch.no_grad():\n    res18.conv1.weight[:,:12] = weight\n    res18.conv1.weight[:, 3] = res18.conv1.weight[:, 0]\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:43.840485Z","iopub.execute_input":"2022-12-13T20:50:43.840897Z","iopub.status.idle":"2022-12-13T20:50:44.315414Z","shell.execute_reply.started":"2022-12-13T20:50:43.840860Z","shell.execute_reply":"2022-12-13T20:50:44.314191Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = res18","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:47.483589Z","iopub.execute_input":"2022-12-13T20:50:47.483967Z","iopub.status.idle":"2022-12-13T20:50:47.489742Z","shell.execute_reply.started":"2022-12-13T20:50:47.483934Z","shell.execute_reply":"2022-12-13T20:50:47.488540Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(res18.parameters())\n#optimizer = torch.optim.Adam(res18.parameters(), lr = 0.00001)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:50.086360Z","iopub.execute_input":"2022-12-13T20:50:50.087165Z","iopub.status.idle":"2022-12-13T20:50:50.094409Z","shell.execute_reply.started":"2022-12-13T20:50:50.087122Z","shell.execute_reply":"2022-12-13T20:50:50.092894Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def train(epoch, model, optimizer):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # send to device\n        data = torch.cat((data[0],data[1],data[2],data[3]),1)\n        data, target = data.to(device), target.to(device)\n        model = model.to(device)\n        output = model(data)\n        criterion = nn.MSELoss()\n        #loss = criterion(output,target)\n        loss = criterion(output.float(),target.float())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n            \n'''\ndef test(model, permute_pixels=None, permutation_order=None):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for batch_idx, (data, target) in enumerate(train_loader):\n        RGBs=torch.stack((data[0][:,:,:,0],data[0][:,:,:,1],data[0][:,:,:,2],\n                          data[1][:,:,:,0],data[1][:,:,:,1],data[1][:,:,:,2],\n                          data[2][:,:,:,0],data[2][:,:,:,1],data[2][:,:,:,2]),1)\n        data=torch.cat((RGBs,data[3]), 1)\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        criterion = nn.MSELoss()\n        loss = criterion(output.float(),target.float())\n        test_loss += loss# sum up batch loss\n        #print(output.shape)\n        #print(output)\n        #pred = output.data.max(1)[1]  # get the index of the max log-probability \n        #print(pred.shape)\n        #print(pred)\n        #print(target.shape)\n        #print(target)\n        #correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        print(output)\n        print(target)\n        correct += np.sqrt(mean_squared_error(output.data, target.data))\n    correct /= len(train_loader.dataset)\n    accuracy = correct\n    print(accuracy)\n    return accuracy\n'''            \n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:50:52.356686Z","iopub.execute_input":"2022-12-13T20:50:52.357108Z","iopub.status.idle":"2022-12-13T20:50:52.369009Z","shell.execute_reply.started":"2022-12-13T20:50:52.357071Z","shell.execute_reply":"2022-12-13T20:50:52.368035Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'\\ndef test(model, permute_pixels=None, permutation_order=None):\\n    model.eval()\\n    test_loss = 0\\n    correct = 0\\n    for batch_idx, (data, target) in enumerate(train_loader):\\n        RGBs=torch.stack((data[0][:,:,:,0],data[0][:,:,:,1],data[0][:,:,:,2],\\n                          data[1][:,:,:,0],data[1][:,:,:,1],data[1][:,:,:,2],\\n                          data[2][:,:,:,0],data[2][:,:,:,1],data[2][:,:,:,2]),1)\\n        data=torch.cat((RGBs,data[3]), 1)\\n        data, target = data.to(device), target.to(device)\\n        optimizer.zero_grad()\\n        output = model(data)\\n        criterion = nn.MSELoss()\\n        loss = criterion(output.float(),target.float())\\n        test_loss += loss# sum up batch loss\\n        #print(output.shape)\\n        #print(output)\\n        #pred = output.data.max(1)[1]  # get the index of the max log-probability \\n        #print(pred.shape)\\n        #print(pred)\\n        #print(target.shape)\\n        #print(target)\\n        #correct += pred.eq(target.data.view_as(pred)).cpu().sum()\\n        print(output)\\n        print(target)\\n        correct += np.sqrt(mean_squared_error(output.data, target.data))\\n    correct /= len(train_loader.dataset)\\n    accuracy = correct\\n    print(accuracy)\\n    return accuracy\\n'"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)\nnum_epochs = 80\n#45\nfor i in range(1,num_epochs+1):\n    train(i, model, optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T22:18:48.591669Z","iopub.execute_input":"2022-12-13T22:18:48.592131Z","iopub.status.idle":"2022-12-13T22:36:14.728051Z","shell.execute_reply.started":"2022-12-13T22:18:48.592094Z","shell.execute_reply":"2022-12-13T22:36:14.726865Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/3396 (0%)]\tLoss: 8.466755\nTrain Epoch: 1 [640/3396 (19%)]\tLoss: 6.351728\nTrain Epoch: 1 [1280/3396 (37%)]\tLoss: 2.809416\nTrain Epoch: 1 [1920/3396 (56%)]\tLoss: 3.993989\nTrain Epoch: 1 [2560/3396 (74%)]\tLoss: 3.975586\nTrain Epoch: 1 [3200/3396 (93%)]\tLoss: 5.377496\nTrain Epoch: 2 [0/3396 (0%)]\tLoss: 5.407528\nTrain Epoch: 2 [640/3396 (19%)]\tLoss: 4.277002\nTrain Epoch: 2 [1280/3396 (37%)]\tLoss: 3.180958\nTrain Epoch: 2 [1920/3396 (56%)]\tLoss: 4.359470\nTrain Epoch: 2 [2560/3396 (74%)]\tLoss: 5.279737\nTrain Epoch: 2 [3200/3396 (93%)]\tLoss: 3.524143\nTrain Epoch: 3 [0/3396 (0%)]\tLoss: 5.514608\nTrain Epoch: 3 [640/3396 (19%)]\tLoss: 4.366031\nTrain Epoch: 3 [1280/3396 (37%)]\tLoss: 7.926670\nTrain Epoch: 3 [1920/3396 (56%)]\tLoss: 5.597160\nTrain Epoch: 3 [2560/3396 (74%)]\tLoss: 5.236538\nTrain Epoch: 3 [3200/3396 (93%)]\tLoss: 4.426623\nTrain Epoch: 4 [0/3396 (0%)]\tLoss: 6.666349\nTrain Epoch: 4 [640/3396 (19%)]\tLoss: 8.127910\nTrain Epoch: 4 [1280/3396 (37%)]\tLoss: 5.446822\nTrain Epoch: 4 [1920/3396 (56%)]\tLoss: 20.011684\nTrain Epoch: 4 [2560/3396 (74%)]\tLoss: 3.298182\nTrain Epoch: 4 [3200/3396 (93%)]\tLoss: 5.261357\nTrain Epoch: 5 [0/3396 (0%)]\tLoss: 5.205634\nTrain Epoch: 5 [640/3396 (19%)]\tLoss: 5.592738\nTrain Epoch: 5 [1280/3396 (37%)]\tLoss: 6.814971\nTrain Epoch: 5 [1920/3396 (56%)]\tLoss: 5.934101\nTrain Epoch: 5 [2560/3396 (74%)]\tLoss: 4.631938\nTrain Epoch: 5 [3200/3396 (93%)]\tLoss: 6.449768\nTrain Epoch: 6 [0/3396 (0%)]\tLoss: 6.836437\nTrain Epoch: 6 [640/3396 (19%)]\tLoss: 4.266678\nTrain Epoch: 6 [1280/3396 (37%)]\tLoss: 3.438694\nTrain Epoch: 6 [1920/3396 (56%)]\tLoss: 5.705211\nTrain Epoch: 6 [2560/3396 (74%)]\tLoss: 3.052343\nTrain Epoch: 6 [3200/3396 (93%)]\tLoss: 3.778868\nTrain Epoch: 7 [0/3396 (0%)]\tLoss: 4.798242\nTrain Epoch: 7 [640/3396 (19%)]\tLoss: 5.491710\nTrain Epoch: 7 [1280/3396 (37%)]\tLoss: 9.433222\nTrain Epoch: 7 [1920/3396 (56%)]\tLoss: 4.182559\nTrain Epoch: 7 [2560/3396 (74%)]\tLoss: 5.515414\nTrain Epoch: 7 [3200/3396 (93%)]\tLoss: 3.114071\nTrain Epoch: 8 [0/3396 (0%)]\tLoss: 7.774811\nTrain Epoch: 8 [640/3396 (19%)]\tLoss: 7.116187\nTrain Epoch: 8 [1280/3396 (37%)]\tLoss: 7.697926\nTrain Epoch: 8 [1920/3396 (56%)]\tLoss: 5.849668\nTrain Epoch: 8 [2560/3396 (74%)]\tLoss: 5.122453\nTrain Epoch: 8 [3200/3396 (93%)]\tLoss: 4.321200\nTrain Epoch: 9 [0/3396 (0%)]\tLoss: 9.156328\nTrain Epoch: 9 [640/3396 (19%)]\tLoss: 10.720527\nTrain Epoch: 9 [1280/3396 (37%)]\tLoss: 7.404097\nTrain Epoch: 9 [1920/3396 (56%)]\tLoss: 5.850533\nTrain Epoch: 9 [2560/3396 (74%)]\tLoss: 9.174279\nTrain Epoch: 9 [3200/3396 (93%)]\tLoss: 5.738894\nTrain Epoch: 10 [0/3396 (0%)]\tLoss: 5.029344\nTrain Epoch: 10 [640/3396 (19%)]\tLoss: 6.701456\nTrain Epoch: 10 [1280/3396 (37%)]\tLoss: 4.183992\nTrain Epoch: 10 [1920/3396 (56%)]\tLoss: 8.653840\nTrain Epoch: 10 [2560/3396 (74%)]\tLoss: 3.501057\nTrain Epoch: 10 [3200/3396 (93%)]\tLoss: 4.845649\nTrain Epoch: 11 [0/3396 (0%)]\tLoss: 5.449238\nTrain Epoch: 11 [640/3396 (19%)]\tLoss: 7.576354\nTrain Epoch: 11 [1280/3396 (37%)]\tLoss: 4.229117\nTrain Epoch: 11 [1920/3396 (56%)]\tLoss: 3.858307\nTrain Epoch: 11 [2560/3396 (74%)]\tLoss: 4.663539\nTrain Epoch: 11 [3200/3396 (93%)]\tLoss: 3.314502\nTrain Epoch: 12 [0/3396 (0%)]\tLoss: 8.312527\nTrain Epoch: 12 [640/3396 (19%)]\tLoss: 6.710018\nTrain Epoch: 12 [1280/3396 (37%)]\tLoss: 4.927641\nTrain Epoch: 12 [1920/3396 (56%)]\tLoss: 3.528270\nTrain Epoch: 12 [2560/3396 (74%)]\tLoss: 2.466678\nTrain Epoch: 12 [3200/3396 (93%)]\tLoss: 4.003254\nTrain Epoch: 13 [0/3396 (0%)]\tLoss: 5.954140\nTrain Epoch: 13 [640/3396 (19%)]\tLoss: 11.191077\nTrain Epoch: 13 [1280/3396 (37%)]\tLoss: 3.463297\nTrain Epoch: 13 [1920/3396 (56%)]\tLoss: 4.881919\nTrain Epoch: 13 [2560/3396 (74%)]\tLoss: 5.586854\nTrain Epoch: 13 [3200/3396 (93%)]\tLoss: 3.107772\nTrain Epoch: 14 [0/3396 (0%)]\tLoss: 6.498617\nTrain Epoch: 14 [640/3396 (19%)]\tLoss: 8.254843\nTrain Epoch: 14 [1280/3396 (37%)]\tLoss: 11.329554\nTrain Epoch: 14 [1920/3396 (56%)]\tLoss: 5.483636\nTrain Epoch: 14 [2560/3396 (74%)]\tLoss: 4.670197\nTrain Epoch: 14 [3200/3396 (93%)]\tLoss: 4.811752\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nnum_epochs = 1\n#45\nfor i in range(1,num_epochs+1):\n    train(i, model, optimizer)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-12-13T17:41:46.795098Z","iopub.execute_input":"2022-12-13T17:41:46.795646Z","iopub.status.idle":"2022-12-13T17:43:41.815762Z","shell.execute_reply.started":"2022-12-13T17:41:46.795597Z","shell.execute_reply":"2022-12-13T17:43:41.812993Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/3396 (0%)]\tLoss: 4284.554199\nTrain Epoch: 1 [640/3396 (19%)]\tLoss: 1563.265991\nTrain Epoch: 1 [1280/3396 (37%)]\tLoss: 798.788940\nTrain Epoch: 1 [1920/3396 (56%)]\tLoss: 572.848267\nTrain Epoch: 1 [2560/3396 (74%)]\tLoss: 561.103760\nTrain Epoch: 1 [3200/3396 (93%)]\tLoss: 503.927612\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(res18.parameters(), lr = 0.00001)\nmodel = model.to(device)\nnum_epochs = 10\nfor i in range(1,num_epochs+1):\n    train(i, model, optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T22:36:31.322203Z","iopub.execute_input":"2022-12-13T22:36:31.322976Z","iopub.status.idle":"2022-12-13T22:48:54.392827Z","shell.execute_reply.started":"2022-12-13T22:36:31.322935Z","shell.execute_reply":"2022-12-13T22:48:54.391777Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/3396 (0%)]\tLoss: 4.280384\nTrain Epoch: 1 [640/3396 (19%)]\tLoss: 4.098396\nTrain Epoch: 1 [1280/3396 (37%)]\tLoss: 4.072707\nTrain Epoch: 1 [1920/3396 (56%)]\tLoss: 2.591498\nTrain Epoch: 1 [2560/3396 (74%)]\tLoss: 3.656499\nTrain Epoch: 1 [3200/3396 (93%)]\tLoss: 3.536957\nTrain Epoch: 2 [0/3396 (0%)]\tLoss: 4.079210\nTrain Epoch: 2 [640/3396 (19%)]\tLoss: 2.027227\nTrain Epoch: 2 [1280/3396 (37%)]\tLoss: 4.497044\nTrain Epoch: 2 [1920/3396 (56%)]\tLoss: 3.530198\nTrain Epoch: 2 [2560/3396 (74%)]\tLoss: 3.315868\nTrain Epoch: 2 [3200/3396 (93%)]\tLoss: 3.634104\nTrain Epoch: 3 [0/3396 (0%)]\tLoss: 2.828182\nTrain Epoch: 3 [640/3396 (19%)]\tLoss: 2.889345\nTrain Epoch: 3 [1280/3396 (37%)]\tLoss: 2.045414\nTrain Epoch: 3 [1920/3396 (56%)]\tLoss: 1.971209\nTrain Epoch: 3 [2560/3396 (74%)]\tLoss: 3.040334\nTrain Epoch: 3 [3200/3396 (93%)]\tLoss: 4.448372\nTrain Epoch: 4 [0/3396 (0%)]\tLoss: 2.568496\nTrain Epoch: 4 [640/3396 (19%)]\tLoss: 2.256904\nTrain Epoch: 4 [1280/3396 (37%)]\tLoss: 4.576478\nTrain Epoch: 4 [1920/3396 (56%)]\tLoss: 2.122996\nTrain Epoch: 4 [2560/3396 (74%)]\tLoss: 4.058206\nTrain Epoch: 4 [3200/3396 (93%)]\tLoss: 2.995315\nTrain Epoch: 5 [0/3396 (0%)]\tLoss: 2.506202\nTrain Epoch: 5 [640/3396 (19%)]\tLoss: 3.137954\nTrain Epoch: 5 [1280/3396 (37%)]\tLoss: 2.262204\nTrain Epoch: 5 [1920/3396 (56%)]\tLoss: 1.805037\nTrain Epoch: 5 [2560/3396 (74%)]\tLoss: 2.190858\nTrain Epoch: 5 [3200/3396 (93%)]\tLoss: 4.386751\nTrain Epoch: 6 [0/3396 (0%)]\tLoss: 3.276493\nTrain Epoch: 6 [640/3396 (19%)]\tLoss: 2.058432\nTrain Epoch: 6 [1280/3396 (37%)]\tLoss: 4.561096\nTrain Epoch: 6 [1920/3396 (56%)]\tLoss: 1.363331\nTrain Epoch: 6 [2560/3396 (74%)]\tLoss: 3.114582\nTrain Epoch: 6 [3200/3396 (93%)]\tLoss: 5.689591\nTrain Epoch: 7 [0/3396 (0%)]\tLoss: 1.871670\nTrain Epoch: 7 [640/3396 (19%)]\tLoss: 2.733463\nTrain Epoch: 7 [1280/3396 (37%)]\tLoss: 1.799432\nTrain Epoch: 7 [1920/3396 (56%)]\tLoss: 2.065907\nTrain Epoch: 7 [2560/3396 (74%)]\tLoss: 3.231113\nTrain Epoch: 7 [3200/3396 (93%)]\tLoss: 1.591995\nTrain Epoch: 8 [0/3396 (0%)]\tLoss: 2.190626\nTrain Epoch: 8 [640/3396 (19%)]\tLoss: 3.125780\nTrain Epoch: 8 [1280/3396 (37%)]\tLoss: 3.130749\nTrain Epoch: 8 [1920/3396 (56%)]\tLoss: 2.128863\nTrain Epoch: 8 [2560/3396 (74%)]\tLoss: 4.405156\nTrain Epoch: 8 [3200/3396 (93%)]\tLoss: 3.234930\nTrain Epoch: 9 [0/3396 (0%)]\tLoss: 2.872667\nTrain Epoch: 9 [640/3396 (19%)]\tLoss: 2.069388\nTrain Epoch: 9 [1280/3396 (37%)]\tLoss: 1.820232\nTrain Epoch: 9 [1920/3396 (56%)]\tLoss: 1.675724\nTrain Epoch: 9 [2560/3396 (74%)]\tLoss: 1.977028\nTrain Epoch: 9 [3200/3396 (93%)]\tLoss: 1.684842\nTrain Epoch: 10 [0/3396 (0%)]\tLoss: 3.662471\nTrain Epoch: 10 [640/3396 (19%)]\tLoss: 1.966712\nTrain Epoch: 10 [1280/3396 (37%)]\tLoss: 3.114454\nTrain Epoch: 10 [1920/3396 (56%)]\tLoss: 2.090572\nTrain Epoch: 10 [2560/3396 (74%)]\tLoss: 1.766644\nTrain Epoch: 10 [3200/3396 (93%)]\tLoss: 1.397392\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(res18.parameters(), lr = 0.000001)\nmodel = model.to(device)\nnum_epochs = 5\nfor i in range(1,num_epochs+1):\n    train(i, model, optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T22:52:04.878200Z","iopub.execute_input":"2022-12-13T22:52:04.878972Z","iopub.status.idle":"2022-12-13T22:58:12.489774Z","shell.execute_reply.started":"2022-12-13T22:52:04.878932Z","shell.execute_reply":"2022-12-13T22:58:12.488365Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/3396 (0%)]\tLoss: 1.256971\nTrain Epoch: 1 [640/3396 (19%)]\tLoss: 1.881082\nTrain Epoch: 1 [1280/3396 (37%)]\tLoss: 1.502058\nTrain Epoch: 1 [1920/3396 (56%)]\tLoss: 2.608703\nTrain Epoch: 1 [2560/3396 (74%)]\tLoss: 2.696876\nTrain Epoch: 1 [3200/3396 (93%)]\tLoss: 3.214560\nTrain Epoch: 2 [0/3396 (0%)]\tLoss: 1.894058\nTrain Epoch: 2 [640/3396 (19%)]\tLoss: 1.759058\nTrain Epoch: 2 [1280/3396 (37%)]\tLoss: 3.499740\nTrain Epoch: 2 [1920/3396 (56%)]\tLoss: 4.704468\nTrain Epoch: 2 [2560/3396 (74%)]\tLoss: 4.144655\nTrain Epoch: 2 [3200/3396 (93%)]\tLoss: 1.493994\nTrain Epoch: 3 [0/3396 (0%)]\tLoss: 1.532415\nTrain Epoch: 3 [640/3396 (19%)]\tLoss: 1.980862\nTrain Epoch: 3 [1280/3396 (37%)]\tLoss: 2.995982\nTrain Epoch: 3 [1920/3396 (56%)]\tLoss: 1.746257\nTrain Epoch: 3 [2560/3396 (74%)]\tLoss: 3.740735\nTrain Epoch: 3 [3200/3396 (93%)]\tLoss: 1.580100\nTrain Epoch: 4 [0/3396 (0%)]\tLoss: 4.808509\nTrain Epoch: 4 [640/3396 (19%)]\tLoss: 1.566144\nTrain Epoch: 4 [1280/3396 (37%)]\tLoss: 2.611864\nTrain Epoch: 4 [1920/3396 (56%)]\tLoss: 1.704734\nTrain Epoch: 4 [2560/3396 (74%)]\tLoss: 1.324081\nTrain Epoch: 4 [3200/3396 (93%)]\tLoss: 2.084518\nTrain Epoch: 5 [0/3396 (0%)]\tLoss: 1.482160\nTrain Epoch: 5 [640/3396 (19%)]\tLoss: 1.756340\nTrain Epoch: 5 [1280/3396 (37%)]\tLoss: 3.616983\nTrain Epoch: 5 [1920/3396 (56%)]\tLoss: 1.706955\nTrain Epoch: 5 [2560/3396 (74%)]\tLoss: 1.844249\nTrain Epoch: 5 [3200/3396 (93%)]\tLoss: 1.809982\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\noptimizer = torch.optim.Adam(res18.parameters(), lr = 0.0000001)\nmodel = model.to(device)\nnum_epochs = 5\nfor i in range(1,num_epochs+1):\n    train(i, model, optimizer)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-12-13T20:48:13.564824Z","iopub.execute_input":"2022-12-13T20:48:13.565251Z","iopub.status.idle":"2022-12-13T20:48:13.572414Z","shell.execute_reply.started":"2022-12-13T20:48:13.565218Z","shell.execute_reply":"2022-12-13T20:48:13.571302Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'\\noptimizer = torch.optim.Adam(res18.parameters(), lr = 0.0000001)\\nmodel = model.to(device)\\nnum_epochs = 5\\nfor i in range(1,num_epochs+1):\\n    train(i, model, optimizer)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"test_data = torch.load(\"/kaggle/input/csci-ua-473-intro-to-machine-learning-fall-2022/test/test/testX.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-12-13T22:58:42.453237Z","iopub.execute_input":"2022-12-13T22:58:42.453970Z","iopub.status.idle":"2022-12-13T22:58:48.167287Z","shell.execute_reply.started":"2022-12-13T22:58:42.453931Z","shell.execute_reply":"2022-12-13T22:58:48.166241Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"\n'''\nfile_ids = test_data[-1]\ndepths = test_data[1]\nrgbs = test_data[0]\n'''\n\n\n#test_dataset = lazyloaddata(\"/kaggle/working/lazydata/\",train = False, transform = transform)\n#test_dataset = lazyloaddata(\"/kaggle/working/lazydata/\",train = False,transform = transform)\n#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n\nfile_ids = test_data[-1]\ndepths = test_data[1]\nrgbs = test_data[0]\ntest_img_data = torch.cat((rgbs[:,0],rgbs[:,1],rgbs[:,2],depths),dim=1)\nsplit_test = torch.split(test_img_data,12,dim=0)\npreds = []\n\nmodel = model.to(device)\n'''\nfor batch_idx, (data, target) in enumerate(test_loader):\n        # send to device\n        data = torch.cat((data[0],data[1],data[2],data[3]),1)\n        data = data.to(device)\n        output = model(data)/1000\n        preds.append(output.cpu().detach().numpy())\n'''\nfor data in split_test:\n    output = model(data.to(device))/1000\n    preds.append(output.cpu().detach().numpy())\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T22:58:54.001908Z","iopub.execute_input":"2022-12-13T22:58:54.002530Z","iopub.status.idle":"2022-12-13T22:58:57.616163Z","shell.execute_reply.started":"2022-12-13T22:58:54.002494Z","shell.execute_reply":"2022-12-13T22:58:57.615147Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"outfile = 'submission.csv'\n\noutput_file = open(outfile, 'w')\n\ntitles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n# preds = []\n\n# test_data = torch.load('./test/test/testX.pt')\n# file_ids = test_data[-1]\n# rgb_data = test_data[0]\n# model.eval()\n\n# for i, data in enumerate(rgb_data):   \n#     # Please remember to modify this loop, input and output based on your model/architecture\n#     output = model(data[:1, :, :, :].to('cuda'))\n#     preds.append(output[0].cpu().detach().numpy())\n\ndf = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(np.concatenate(preds))], axis = 1, names = titles)\ndf.columns = titles\ndf.to_csv(outfile, index = False)\nprint(\"Written to csv file {}\".format(outfile))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T22:59:02.731145Z","iopub.execute_input":"2022-12-13T22:59:02.732176Z","iopub.status.idle":"2022-12-13T22:59:02.759170Z","shell.execute_reply.started":"2022-12-13T22:59:02.732133Z","shell.execute_reply":"2022-12-13T22:59:02.758243Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Written to csv file submission.csv\n","output_type":"stream"}]}]}